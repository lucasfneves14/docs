---
title: 'The Very Quick GraphorLM Quickstart'
description: 'Build your first RAG pipeline in minutes'
---

This quickstart gets you up and running with GraphorLM as quickly as possible. It introduces you to the platform's interface and core RAG pipeline components without diving into technical details or complex configurations.

In this tutorial, you will:
- Load documents into GraphorLM
- Configure a basic RAG pipeline with intelligent chunking
- Test your pipeline with sample queries

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/quickstart-flow.png"
  alt="GraphorLM RAG Pipeline"
/>

## Step one: Set up GraphorLM

This quickstart uses the GraphorLM Cloud platform. A free trial is available for new users.

1. Sign up for a [GraphorLM Cloud account](https://cloud.graphorlm.com/signup)
2. Once logged in, you'll see the GraphorLM dashboard
3. Select **Create New Project** and name it "QuickstartRAG"

## Step two: Load documents

GraphorLM provides sample documents to get you started without needing to upload your own files.

1. In your project, navigate to **Data Sources** in the left sidebar
2. Click **Add Data Source** and select **Sample Documents**
3. Choose the "Technical Documentation" sample collection
4. Click **Import** to load these documents into your project

These documents contain technical information that we'll use to build and test our RAG pipeline.

## Step three: Create a RAG pipeline

Now let's create a simple RAG pipeline using the imported documents.

1. In the left sidebar, click **Pipelines** > **Create New Pipeline**
2. Name your pipeline "QuickstartPipeline"
3. You'll see the visual pipeline builder with the following components:
   - **Data Source**: Where your documents come from
   - **Chunking**: How documents are split for processing
   - **Embedding**: How text is converted to vector representations
   - **Storage**: Where the processed data is stored
   - **Retrieval**: How relevant information is fetched
   - **Generation**: How responses are created using an LLM

## Step four: Configure pipeline components

Now let's set up the key components of your pipeline:

1. Click on the **Data Source** component
   - Select the "Technical Documentation" source you imported earlier
   - Keep the default OCR settings

2. Click on the **Chunking** component
   - Set Chunk Size to 1000
   - Set Chunk Overlap to 200
   - Select "Semantic" as the chunking method

3. Click on the **Embedding** component
   - Choose "OpenAI" as the embedding model
   - Select "text-embedding-3-small" from the dropdown

4. Click on the **LLM** component
   - Choose "OpenAI" as the provider
   - Select "gpt-3.5-turbo" as the model

5. Click **Save Pipeline** at the top right

## Step five: Test your RAG pipeline

Let's test the pipeline with some sample queries:

1. Navigate to the **Chat** tab in the left sidebar
2. Select your "QuickstartPipeline" from the dropdown
3. Type a question related to the technical documentation, such as: "What are the system requirements?"
4. Click **Send** to see the response

The response combines information retrieved from the documents with natural language generation from the LLM. Notice how the system:
- Retrieves relevant chunks from the documentation
- Highlights the source of information
- Provides a coherent response

## Next steps

Congratulations! You've built and tested your first RAG pipeline with GraphorLM. Here's what you can explore next:

- Learn how to [upload your own documents](/guides/data-ingestion)
- Explore [advanced chunking strategies](/guides/chunking) for better retrieval
- Understand [evaluation metrics](/guides/evaluation) to improve your RAG pipeline
- Connect your pipeline to [external applications](/guides/integrate-workflow) via API
