---
title: 'Quickstart'
description: 'Build your first RAG pipeline in minutes'
---

This quickstart gets you up and running with GraphorLM as quickly as possible. It introduces you to the platform's interface and core RAG pipeline components without diving into technical details or complex configurations.

In this tutorial, you will:
- Load your data into GraphorLM
- Configure a basic RAG pipeline with intelligent chunking
- Test your pipeline

## Step one: Set up GraphorLM Project

GraphorLM Cloud provides a fully-managed environment where you can build, test, and deploy RAG pipelines without worrying about infrastructure or complex setup. The free trial gives you full access to all platform features.

1. Sign up for a [GraphorLM Cloud account](https://app.graphorlm.com/register)
2. Login to your account [Login](https://app.graphorlm.com/login)
2. Once logged in, you'll see the GraphorLM dashboard
3. Select **New project** and name it as you want

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/project-list-demo.png"
  alt="Project list demo"
/>

Once your project is created, you'll be taken to the sources dashboard where you can begin building your RAG pipeline.

## Step two: Load your data

GraphorLM allows you to easily upload your own documents to use in your RAG pipeline.

1. In your project, navigate to **Sources** in the left sidebar
2. Click **Add Sources** to open the data upload interface
3. Choose your preferred import method:
   - **Local files**: Upload files from your computer (PDF, MD, PNG, JPG, DOCX, TXT, CSV and others are supported)
   - **URL**: Import content directly from a web address
4. Select or drag and drop your files into the upload area
5. Click **Finish** to begin the ingestion process

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/sources-demo.png"
  alt="Sources demo"
/>

During processing, GraphorLM will automatically:
- Extract text using advanced OCR for images and scanned documents
- Identify document structure and metadata
- Prepare your content for chunking in the pipeline

You can monitor the ingestion progress on the Sources dashboard.

After upload, you can click on any file to:
- Customize the parsing method and configure element classification to improve document structure recognition
- Preview the extracted content before pipeline processing

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/parsing-demo.png"
  alt="Parsing demo"
/>


## Step three: Create a RAG pipeline

Now let's create a simple RAG pipeline using the imported documents.

1. In the left sidebar, click **Pipelines** > **Create New Pipeline**
2. Name your pipeline "QuickstartPipeline"
3. You'll see the visual pipeline builder with the following components:
   - **Data Source**: Where your documents come from
   - **Chunking**: How documents are split for processing
   - **Embedding**: How text is converted to vector representations
   - **Storage**: Where the processed data is stored
   - **Retrieval**: How relevant information is fetched
   - **Generation**: How responses are created using an LLM

## Step four: Configure pipeline components

Now let's set up the key components of your pipeline:

1. Click on the **Data Source** component
   - Select the "Technical Documentation" source you imported earlier
   - Keep the default OCR settings

2. Click on the **Chunking** component
   - Set Chunk Size to 1000
   - Set Chunk Overlap to 200
   - Select "Semantic" as the chunking method

3. Click on the **Embedding** component
   - Choose "OpenAI" as the embedding model
   - Select "text-embedding-3-small" from the dropdown

4. Click on the **LLM** component
   - Choose "OpenAI" as the provider
   - Select "gpt-3.5-turbo" as the model

5. Click **Save Pipeline** at the top right

## Step five: Test your RAG pipeline

Let's test the pipeline with some sample queries:

1. Navigate to the **Chat** tab in the left sidebar
2. Select your "QuickstartPipeline" from the dropdown
3. Type a question related to the technical documentation, such as: "What are the system requirements?"
4. Click **Send** to see the response

The response combines information retrieved from the documents with natural language generation from the LLM. Notice how the system:
- Retrieves relevant chunks from the documentation
- Highlights the source of information
- Provides a coherent response

## Next steps

Congratulations! You've built and tested your first RAG pipeline with GraphorLM. Here's what you can explore next:

- Learn how to [upload your own documents](/guides/data-ingestion)
- Explore [advanced chunking strategies](/guides/chunking) for better retrieval
- Understand [evaluation metrics](/guides/evaluation) to improve your RAG pipeline
- Connect your pipeline to [external applications](/guides/integrate-workflow) via API
