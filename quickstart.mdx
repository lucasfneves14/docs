---
title: 'Quickstart'
description: 'Build your first RAG pipeline in minutes'
---

This quickstart gets you up and running with GraphorLM as quickly as possible. It introduces you to the platform's interface and core RAG pipeline components without diving into technical details or complex configurations.

In this tutorial, you will:
- Load your data into GraphorLM
- Configure a basic RAG pipeline with intelligent chunking
- Test your pipeline

## Step one: Set up GraphorLM Project

GraphorLM Cloud provides a fully-managed environment where you can build, test, and deploy RAG pipelines without worrying about infrastructure or complex setup. The free trial gives you full access to all platform features.

1. Sign up for a [GraphorLM Cloud account](https://app.graphorlm.com/register)
2. Login to your account [Login](https://app.graphorlm.com/login)
2. Once logged in, you'll see the GraphorLM dashboard
3. Select **New project** and name it as you want

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/project-list-demo.png"
  alt="Project list demo"
/>

Once your project is created, you'll be taken to the sources dashboard where you can begin building your RAG pipeline.

## Step two: Load your data

GraphorLM allows you to easily upload your own documents to use in your RAG pipeline.

1. In your project, navigate to **Sources** in the left sidebar
2. Click **Add Sources** to open the data upload interface
3. Choose your preferred import method:
   - **Local files**: Upload files from your computer (PDF, MD, PNG, JPG, DOCX, TXT, CSV and others are supported)
   - **URL**: Import content directly from a web address
4. Select or drag and drop your files into the upload area
5. Click **Finish** to begin the ingestion process

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/sources-demo.png"
  alt="Sources demo"
/>

During processing, GraphorLM will automatically:
- Extract text using advanced OCR for images and scanned documents
- Identify document structure and metadata
- Prepare your content for chunking in the pipeline

You can monitor the ingestion progress on the Sources dashboard.

After upload, you can click on any file to:
- Customize the parsing method and configure element classification to improve document structure recognition
- Preview the extracted content before pipeline processing

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/parsing-demo.png"
  alt="Parsing demo"
/>

## Step three: Create a RAG pipeline

Now let's create a RAG flow to process your documents and build an intelligent question-answering system.

1. In the left sidebar, click **Flows** to navigate to the Flows dashboard
2. Click **New flow** to start creating your pipeline
3. Enter a descriptive name for your flow (e.g., "DocumentQA")
4. Click **Create** to open the visual flow builder

You'll see the visual flow builder interface with components that can be connected to form your RAG pipeline:

- **Dataset**: Select the documents you uploaded in the previous step
- **Chunking**: Configure how your documents are segmented for optimal retrieval
- **Retrieval**: Define how relevant information is searched and ranked
- **Testset**: Create evaluation scenarios with ground-truth answers
- **Questions**: Define sample queries to test your pipeline
- **LLM**: Connect to language models for generating responses
- **Evaluation**: Measure the quality and accuracy of your pipeline
- **Response**: View the final output of your RAG system

<img
  className="block border rounded-2xl border-gray-950\/10 ring-2 ring-transparent"
  src="/images/blank-flow-demo.png"
  alt="Blank flow demo"
/>

The flow builder uses a drag-and-drop interface where you can connect these components to create your custom RAG pipeline.

## Step four: Configure pipeline components

Now let's set up the key components of your pipeline:

1. Click on the **Data Source** component
   - Select the "Technical Documentation" source you imported earlier
   - Keep the default OCR settings

2. Click on the **Chunking** component
   - Set Chunk Size to 1000
   - Set Chunk Overlap to 200
   - Select "Semantic" as the chunking method

3. Click on the **Embedding** component
   - Choose "OpenAI" as the embedding model
   - Select "text-embedding-3-small" from the dropdown

4. Click on the **LLM** component
   - Choose "OpenAI" as the provider
   - Select "gpt-3.5-turbo" as the model

5. Click **Save Pipeline** at the top right

## Step five: Test your RAG pipeline

Let's test the pipeline with some sample queries:

1. Navigate to the **Chat** tab in the left sidebar
2. Select your "QuickstartPipeline" from the dropdown
3. Type a question related to the technical documentation, such as: "What are the system requirements?"
4. Click **Send** to see the response

The response combines information retrieved from the documents with natural language generation from the LLM. Notice how the system:
- Retrieves relevant chunks from the documentation
- Highlights the source of information
- Provides a coherent response

## Next steps

Congratulations! You've built and tested your first RAG pipeline with GraphorLM. Here's what you can explore next:

- Learn how to [upload your own documents](/guides/data-ingestion)
- Explore [advanced chunking strategies](/guides/chunking) for better retrieval
- Understand [evaluation metrics](/guides/evaluation) to improve your RAG pipeline
- Connect your pipeline to [external applications](/guides/integrate-workflow) via API
